server.port=8088
spring.profiles.active=dev

#######################> Logging Configs <#############################
logging.level.root=info
#logging.level.com.lankydan.service=debug
logging.path=logs
logging.file=${logging.path}/application.log
logging.pattern.file=%d{dd-MM-yyyy HH:mm:ss.SSS} [%thread] %-5level %logger{36}.%M - %msg%n
logging.pattern.console=%d{dd-MM-yyyy HH:mm:ss.SSS} %magenta([%thread]) %highlight(%-5level) %logger.%M - %msg%n


#######################> Kafka Configs <#############################
spring.kafka.listener.concurrency=3
kafka.default.topic=mytopic
kafka.bootstrapAddress=127.0.0.1:9092
kafka.default.group.id=default.group.id
kafka.user.json.topic=user-default-topic-1

#######################> Kafka Server Configs <#############################
##spring.kafka.admin.client-id
#spring.kafka.bootstrap-servers=127.0.0.1:9092

##Producer Serialization:
##Serializer class for keys.
#spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
##Serializer class for values.
#spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer

##############################Other properties###########################################################

#Frequency with which the consumer offsets are auto-committed to Kafka if 'enable.auto.commit' is set to true.
#spring.kafka.consumer.auto-commit-interval=


#What to do when there is no initial offset in Kafka or if the current offset no longer exists on the server.
#spring.kafka.consumer.auto-offset-reset=


#Comma-delimited list of host:port pairs to use for establishing the initial connections to the Kafka cluster. Overrides the global property, for consumers.
#spring.kafka.consumer.bootstrap-servers=


#ID to pass to the server when making requests. Used for server-side logging.
#spring.kafka.consumer.client-id=


#Whether the consumer's offset is periodically committed in the background.
#spring.kafka.consumer.enable-auto-commit=


#Maximum amount of time the server blocks before answering the fetch request if there isn't sufficient data to immediately satisfy the requirement given by "fetch-min-size".
#spring.kafka.consumer.fetch-max-wait=


#Minimum amount of data the server should return for a fetch request.
#spring.kafka.consumer.fetch-min-size=


#Unique string that identifies the consumer group to which this consumer belongs.
#spring.kafka.consumer.group-id=

#Expected time between heartbeats to the consumer coordinator.
#spring.kafka.consumer.heartbeat-interval=


#Isolation level for reading messages that have been written transactionally.
#spring.kafka.consumer.isolation-level=


#Deserializer class for keys.
#spring.kafka.consumer.key-deserializer=


#Maximum number of records returned in a single call to poll().
#spring.kafka.consumer.max-poll-records=


#Additional consumer-specific properties used to configure the client.
#spring.kafka.consumer.properties.*=


#Deserializer class for values.
#spring.kafka.consumer.value-deserializer=


#Control flag for login configuration.
#spring.kafka.jaas.control-flag=


#Whether to enable JAAS configuration.
#spring.kafka.jaas.enabled=


#Login module. ##com.sun.security.auth.module.Krb5LoginModule
#spring.kafka.jaas.login-module=


#Additional JAAS options.
#spring.kafka.jaas.options.*=

#Number of records between offset commits when ackMode is "COUNT" or "COUNT_TIME".
#spring.kafka.listener.ack-count=


#Listener AckMode. See the spring-kafka documentation.
#spring.kafka.listener.ack-mode=


#Time between offset commits when ackMode is "TIME" or "COUNT_TIME".
#spring.kafka.listener.ack-time=


#Prefix for the listener's consumer client.id property.
#spring.kafka.listener.client-id=


#Number of threads to run in the listener containers.
#spring.kafka.listener.concurrency=


#Time between publishing idle consumer events (no data received).
#spring.kafka.listener.idle-event-interval=


#Whether to log the container configuration during initialization (INFO level).
#spring.kafka.listener.log-container-config=


#Whether the container should fail to start if at least one of the configured topics are not present on the broker.
#spring.kafka.listener.missing-topics-fatal=   ## default true


#Time between checks for non-responsive consumers. If a duration suffix is not specified, seconds will be used.
#spring.kafka.listener.monitor-interval=


#Multiplier applied to "pollTimeout" to determine if a consumer is non-responsive.
#spring.kafka.listener.no-poll-threshold=


#Timeout to use when polling the consumer.
#spring.kafka.listener.poll-timeout=


#Listener type.
#spring.kafka.listener.type= ##default single


#Number of acknowledgments the producer requires the leader to have received before considering a request complete.
#spring.kafka.producer.acks=


#Default batch size. A small batch size will make batching less common and may reduce throughput (a batch size of zero disables batching entirely).
#spring.kafka.producer.batch-size=


#Comma-delimited list of host:port pairs to use for establishing the initial connections to the Kafka cluster. Overrides the global property, for producers.
#spring.kafka.producer.bootstrap-servers=


#Total memory size the producer can use to buffer records waiting to be sent to the server.
#spring.kafka.producer.buffer-memory=


#ID to pass to the server when making requests. Used for server-side logging.
#spring.kafka.producer.client-id=


#Compression type for all data generated by the producer.
#spring.kafka.producer.compression-type=


#Additional producer-specific properties used to configure the client.
#spring.kafka.producer.properties.*=


#When greater than zero, enables retrying of failed sends.
#spring.kafka.producer.retries=


#When non empty, enables transaction support for producer.
#spring.kafka.producer.transaction-id-prefix


#Additional properties, common to producers and consumers, used to configure the client.
#spring.kafka.properties.*


#Default topic to which messages are sent.
#spring.kafka.template.default-topic
